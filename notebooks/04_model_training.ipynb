{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aedc448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25bc5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_feature_engineering(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Log-transform amount\n",
    "    df['log_amount'] = np.log1p(df['amount'])\n",
    "    \n",
    "    # Create binary feature for nighttime transactions\n",
    "    if 'transaction_hour' in df.columns:\n",
    "        df['is_night'] = df['transaction_hour'].apply(lambda x: 1 if (x >= 22 or x < 5) else 0)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a6829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudModelPipeline:\n",
    "    def __init__(self, numeric_features, categorical_features):\n",
    "        self.numeric_features = numeric_features\n",
    "        self.categorical_features = categorical_features\n",
    "        self.pipeline = None\n",
    "        self.model = None\n",
    "    \n",
    "    def build_preprocessing_pipeline(self):\n",
    "        \"\"\"Builds preprocessing pipeline\"\"\"\n",
    "        custom_transformer = FunctionTransformer(custom_feature_engineering)\n",
    "\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, self.numeric_features),\n",
    "                ('cat', categorical_transformer, self.categorical_features)\n",
    "            ],\n",
    "            remainder='drop'\n",
    "        )\n",
    "\n",
    "        preprocessing_pipeline = Pipeline(steps=[\n",
    "            ('custom_features', custom_transformer),\n",
    "            ('preprocessor', preprocessor)\n",
    "        ])\n",
    "        \n",
    "        return preprocessing_pipeline\n",
    "\n",
    "    def build_full_pipeline(self):\n",
    "        \"\"\"Combine preprocessing + model into full pipeline\"\"\"\n",
    "        preprocessor = self.build_preprocessing_pipeline()\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=10,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "        self.pipeline = full_pipeline\n",
    "\n",
    "    def train(self, df, target_col):\n",
    "        \"\"\"Train model\"\"\"\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        print(\" Training model...\")\n",
    "        self.build_full_pipeline()\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "\n",
    "        print(\" Model training complete.\")\n",
    "\n",
    "        y_pred = self.pipeline.predict(X_test)\n",
    "        y_prob = self.pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        print(\"\\n Evaluation Results:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "        return X_test, y_test, y_pred\n",
    "\n",
    "    def save_artifacts(self, path_prefix=\"../artifacts\"):\n",
    "        \"\"\"Save preprocessing + model pipeline\"\"\"\n",
    "        joblib.dump(self.pipeline, f\"{path_prefix}/fraud_detection_pipeline.pkl\")\n",
    "        print(f\" Saved full pipeline to {path_prefix}/fraud_detection_pipeline.pkl\")\n",
    "\n",
    "    def load_artifacts(self, path):\n",
    "        \"\"\"Load preprocessing + model pipeline\"\"\"\n",
    "        self.pipeline = joblib.load(path)\n",
    "        print(\" Loaded pipeline artifact.\")\n",
    "\n",
    "    def predict(self, new_data: pd.DataFrame):\n",
    "        \"\"\"Predict on new data\"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"Pipeline not loaded. Call load_artifacts() first.\")\n",
    "        return self.pipeline.predict(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "numeric_features = [\n",
    "    'amount', 'amount_scaled', 'customer_avg_amount',\n",
    "    'customer_std_amount', 'transaction_frequency',\n",
    "    'distance_from_home', 'transaction_hour'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'device_type', 'location', 'merchant_category', 'channel'\n",
    "]\n",
    "\n",
    "# Initialize and train\n",
    "fraud_pipeline = FraudModelPipeline(numeric_features, categorical_features)\n",
    "X_test, y_test, y_pred = fraud_pipeline.train(df, target_col='is_fraud')\n",
    "\n",
    "# Save artifacts\n",
    "fraud_pipeline.save_artifacts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27200637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline\n",
    "fraud_pipeline.load_artifacts(\"../artifacts/fraud_detection_pipeline.pkl\")\n",
    "\n",
    "# Inference on new transactions\n",
    "new_txn = df.sample(3, random_state=42).drop(columns=['is_fraud'])\n",
    "preds = fraud_pipeline.predict(new_txn)\n",
    "\n",
    "print(\"Predictions:\", preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
